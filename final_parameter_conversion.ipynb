{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8876367-0a44-4575-83bf-59ab763bdfdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T16:23:26.821050Z",
     "iopub.status.busy": "2024-05-18T16:23:26.820835Z",
     "iopub.status.idle": "2024-05-18T16:23:26.894793Z",
     "shell.execute_reply": "2024-05-18T16:23:26.894268Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a30ed6-b94f-41f9-a82e-e200a812b7fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T16:23:26.897757Z",
     "iopub.status.busy": "2024-05-18T16:23:26.897490Z",
     "iopub.status.idle": "2024-05-18T16:23:26.901071Z",
     "shell.execute_reply": "2024-05-18T16:23:26.900438Z"
    }
   },
   "outputs": [],
   "source": [
    "#mdm_data = np.load('/home/rishabhswapnil/priorMDM/save/my_humanml_trans_enc_512/DoubleTake_samples_my_humanml_trans_enc_512_000200000_seed10_dt_text_example_handshake_20_double_take_blend_10_skipSteps_100/results.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea3baa2c-01db-42c1-a963-d99e57e44bbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T16:23:26.903986Z",
     "iopub.status.busy": "2024-05-18T16:23:26.903781Z",
     "iopub.status.idle": "2024-05-18T16:23:28.080093Z",
     "shell.execute_reply": "2024-05-18T16:23:28.079322Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "# https://pytorch3d.readthedocs.io/en/latest/_modules/pytorch3d/transforms/rotation_conversions.html#matrix_to_quaternion\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def _copysign(a, b):\n",
    "    \"\"\"\n",
    "    Return a tensor where each element has the absolute value taken from the,\n",
    "    corresponding element of a, with sign taken from the corresponding\n",
    "    element of b. This is like the standard copysign floating-point operation,\n",
    "    but is not careful about negative 0 and NaN.\n",
    "    Args:\n",
    "        a: source tensor.\n",
    "        b: tensor whose signs will be used, of the same shape as a.\n",
    "    Returns:\n",
    "        Tensor of the same shape as a with the signs of b.\n",
    "    \"\"\"\n",
    "    signs_differ = (a < 0) != (b < 0)\n",
    "    return torch.where(signs_differ, -a, a)\n",
    "\n",
    "def _sqrt_positive_part(x):\n",
    "    \"\"\"\n",
    "    Returns torch.sqrt(torch.max(0, x))\n",
    "    but with a zero subgradient where x is 0.\n",
    "    \"\"\"\n",
    "    ret = torch.zeros_like(x)\n",
    "    positive_mask = x > 0\n",
    "    ret[positive_mask] = torch.sqrt(x[positive_mask])\n",
    "    return ret\n",
    "\n",
    "def matrix_to_quaternion(matrix):\n",
    "    \"\"\"\n",
    "    Convert rotations given as rotation matrices to quaternions.\n",
    "    Args:\n",
    "        matrix: Rotation matrices as tensor of shape (..., 3, 3).\n",
    "    Returns:\n",
    "        quaternions with real part first, as tensor of shape (..., 4).\n",
    "    \"\"\"\n",
    "    if matrix.size(-1) != 3 or matrix.size(-2) != 3:\n",
    "        raise ValueError(f\"Invalid rotation matrix  shape f{matrix.shape}.\")\n",
    "    m00 = matrix[..., 0, 0]\n",
    "    m11 = matrix[..., 1, 1]\n",
    "    m22 = matrix[..., 2, 2]\n",
    "    o0 = 0.5 * _sqrt_positive_part(1 + m00 + m11 + m22)\n",
    "    x = 0.5 * _sqrt_positive_part(1 + m00 - m11 - m22)\n",
    "    y = 0.5 * _sqrt_positive_part(1 - m00 + m11 - m22)\n",
    "    z = 0.5 * _sqrt_positive_part(1 - m00 - m11 + m22)\n",
    "    o1 = _copysign(x, matrix[..., 2, 1] - matrix[..., 1, 2])\n",
    "    o2 = _copysign(y, matrix[..., 0, 2] - matrix[..., 2, 0])\n",
    "    o3 = _copysign(z, matrix[..., 1, 0] - matrix[..., 0, 1])\n",
    "\n",
    "    return torch.stack((o0, o1, o2, o3), -1)\n",
    "\n",
    "def quaternion_to_axis_angle(quaternions):\n",
    "    \"\"\"\n",
    "    Convert rotations given as quaternions to axis/angle.\n",
    "    Args:\n",
    "        quaternions: quaternions with real part first,\n",
    "            as tensor of shape (..., 4).\n",
    "    Returns:\n",
    "        Rotations given as a vector in axis angle form, as a tensor\n",
    "            of shape (..., 3), where the magnitude is the angle\n",
    "            turned anticlockwise in radians around the vector's\n",
    "            direction.\n",
    "    \"\"\"\n",
    "    norms = torch.norm(quaternions[..., 1:], p=2, dim=-1, keepdim=True)\n",
    "    half_angles = torch.atan2(norms, quaternions[..., :1])\n",
    "    angles = 2 * half_angles\n",
    "    eps = 1e-6\n",
    "    small_angles = angles.abs() < eps\n",
    "    sin_half_angles_over_angles = torch.empty_like(angles)\n",
    "    sin_half_angles_over_angles[~small_angles] = (\n",
    "        torch.sin(half_angles[~small_angles]) / angles[~small_angles]\n",
    "    )\n",
    "    # for x small, sin(x/2) is about x/2 - (x/2)^3/6\n",
    "    # so sin(x/2)/x is about 1/2 - (x*x)/48\n",
    "    sin_half_angles_over_angles[small_angles] = (\n",
    "        0.5 - (angles[small_angles] * angles[small_angles]) / 48\n",
    "    )\n",
    "\n",
    "    return quaternions[..., 1:] / sin_half_angles_over_angles\n",
    "\n",
    "\n",
    "def rotation_6d_to_matrix(d6):\n",
    "    \"\"\" \n",
    "    Converts 6D rotation representation by Zhou et al. [1] to rotation matrix \n",
    "    using Gram--Schmidt orthogonalisation per Section B of [1]. \n",
    "    Args: \n",
    "        d6: 6D rotation representation, of size (*, 6) \n",
    "\n",
    "    Returns: \n",
    "        batch of rotation matrices of size (*, 3, 3) \n",
    "\n",
    "    [1] Zhou, Y., Barnes, C., Lu, J., Yang, J., & Li, H. \n",
    "    On the Continuity of Rotation Representations in Neural Networks. \n",
    "    IEEE Conference on Computer Vision and Pattern Recognition, 2019. \n",
    "    Retrieved from http://arxiv.org/abs/1812.07035 \n",
    "    \"\"\" \n",
    "\n",
    "    a1, a2 = d6[..., :3], d6[..., 3:] \n",
    "    b1 = F.normalize(a1, dim=-1) \n",
    "    b2 = a2 - (b1 * a2).sum(-1, keepdim=True) * b1 \n",
    "    b2 = F.normalize(b2, dim=-1) \n",
    "    b3 = torch.cross(b1, b2, dim=-1)\n",
    "\n",
    "    return torch.stack((b1, b2, b3), dim=-2) \n",
    "\n",
    "def matrix_to_axis_angle(matrix):\n",
    "    \"\"\" \n",
    "    Convert rotations given as rotation matrices to axis/angle. \n",
    "\n",
    "    Args: \n",
    "        matrix: Rotation matrices as tensor of shape (..., 3, 3). \n",
    "\n",
    "    Returns: \n",
    "        Rotations given as a vector in axis angle form, as a tensor \n",
    "            of shape (..., 3), where the magnitude is the angle \n",
    "            turned anticlockwise in radians around the vector's \n",
    "            direction. \n",
    "    \"\"\"\n",
    "\n",
    "    return quaternion_to_axis_angle(matrix_to_quaternion(matrix)) \n",
    "\n",
    "def matrix_to_rotation_6d(matrix: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Converts rotation matrices to 6D rotation representation by Zhou et al. [1]\n",
    "    by dropping the last row. Note that 6D representation is not unique.\n",
    "    Args:\n",
    "        matrix: batch of rotation matrices of size (*, 3, 3)\n",
    "\n",
    "    Returns:\n",
    "        6D rotation representation, of size (*, 6)\n",
    "\n",
    "    [1] Zhou, Y., Barnes, C., Lu, J., Yang, J., & Li, H.\n",
    "    On the Continuity of Rotation Representations in Neural Networks.\n",
    "    IEEE Conference on Computer Vision and Pattern Recognition, 2019.\n",
    "    Retrieved from http://arxiv.org/abs/1812.07035\n",
    "    \"\"\"\n",
    "    batch_dim = matrix.size()[:-2]\n",
    "    return matrix[..., :2, :].clone().reshape(batch_dim + (6,))\n",
    "\n",
    "def axis_angle_to_matrix(axis_angle: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert rotations given as axis/angle to rotation matrices.\n",
    "\n",
    "    Args:\n",
    "        axis_angle: Rotations given as a vector in axis angle form,\n",
    "            as a tensor of shape (..., 3), where the magnitude is\n",
    "            the angle turned anticlockwise in radians around the\n",
    "            vector's direction.\n",
    "\n",
    "    Returns:\n",
    "        Rotation matrices as tensor of shape (..., 3, 3).\n",
    "    \"\"\"\n",
    "    return quaternion_to_matrix(axis_angle_to_quaternion(axis_angle))\n",
    "\n",
    "\n",
    "def axis_angle_to_quaternion(axis_angle: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert rotations given as axis/angle to quaternions.\n",
    "\n",
    "    Args:\n",
    "        axis_angle: Rotations given as a vector in axis angle form,\n",
    "            as a tensor of shape (..., 3), where the magnitude is\n",
    "            the angle turned anticlockwise in radians around the\n",
    "            vector's direction.\n",
    "\n",
    "    Returns:\n",
    "        quaternions with real part first, as tensor of shape (..., 4).\n",
    "    \"\"\"\n",
    "    angles = torch.norm(axis_angle, p=2, dim=-1, keepdim=True)\n",
    "    half_angles = angles * 0.5\n",
    "    eps = 1e-6\n",
    "    small_angles = angles.abs() < eps\n",
    "    sin_half_angles_over_angles = torch.empty_like(angles)\n",
    "    sin_half_angles_over_angles[~small_angles] = (\n",
    "        torch.sin(half_angles[~small_angles]) / angles[~small_angles]\n",
    "    )\n",
    "    # for x small, sin(x/2) is about x/2 - (x/2)^3/6\n",
    "    # so sin(x/2)/x is about 1/2 - (x*x)/48\n",
    "    sin_half_angles_over_angles[small_angles] = (\n",
    "        0.5 - (angles[small_angles] * angles[small_angles]) / 48\n",
    "    )\n",
    "    quaternions = torch.cat(\n",
    "        [torch.cos(half_angles), axis_angle * sin_half_angles_over_angles],\n",
    "        dim=-1,\n",
    "    )\n",
    "    return quaternions\n",
    "\n",
    "\n",
    "def quaternion_to_matrix(quaternions: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert rotations given as quaternions to rotation matrices.\n",
    "\n",
    "    Args:\n",
    "        quaternions: quaternions with real part first,\n",
    "            as tensor of shape (..., 4).\n",
    "\n",
    "    Returns:\n",
    "        Rotation matrices as tensor of shape (..., 3, 3).\n",
    "    \"\"\"\n",
    "    r, i, j, k = torch.unbind(quaternions, -1)\n",
    "    two_s = 2.0 / (quaternions * quaternions).sum(-1)\n",
    "\n",
    "    o = torch.stack(\n",
    "        (\n",
    "            1 - two_s * (j * j + k * k),\n",
    "            two_s * (i * j - k * r),\n",
    "            two_s * (i * k + j * r),\n",
    "            two_s * (i * j + k * r),\n",
    "            1 - two_s * (i * i + k * k),\n",
    "            two_s * (j * k - i * r),\n",
    "            two_s * (i * k - j * r),\n",
    "            two_s * (j * k + i * r),\n",
    "            1 - two_s * (i * i + j * j),\n",
    "        ),\n",
    "        -1,\n",
    "    )\n",
    "    return o.reshape(quaternions.shape[:-1] + (3, 3))\n",
    "\n",
    "\n",
    "def _sqrt_positive_part(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Returns torch.sqrt(torch.max(0, x))\n",
    "    but with a zero subgradient where x is 0.\n",
    "    \"\"\"\n",
    "    ret = torch.zeros_like(x)\n",
    "    positive_mask = x > 0\n",
    "    ret[positive_mask] = torch.sqrt(x[positive_mask])\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf9feeb-8a4c-417e-b6bb-9d338e56f820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T16:23:28.083383Z",
     "iopub.status.busy": "2024-05-18T16:23:28.082829Z",
     "iopub.status.idle": "2024-05-18T16:23:28.404285Z",
     "shell.execute_reply": "2024-05-18T16:23:28.403446Z"
    }
   },
   "outputs": [],
   "source": [
    "pose_path = '/home/rishabhswapnil/priorMDM/save/my_humanml_trans_enc_512/DoubleTake_samples_my_humanml_trans_enc_512_000200000_seed10_dt_csv_example_handshake_20_double_take_blend_10_skipSteps_100/sample00_rep00_smpl_params.npy'\n",
    "poses = np.load(pose_path, allow_pickle=True).item()['thetas']\n",
    "transl = np.load(pose_path, allow_pickle=True).item()['root_translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed60b264-cb65-4064-abab-e61738ed8bad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T16:23:28.407564Z",
     "iopub.status.busy": "2024-05-18T16:23:28.407345Z",
     "iopub.status.idle": "2024-05-18T16:23:29.545143Z",
     "shell.execute_reply": "2024-05-18T16:23:29.544564Z"
    }
   },
   "outputs": [],
   "source": [
    "pose_output = []\n",
    "\n",
    "# Iterate over the third dimension of the poses array\n",
    "for idx in range(poses.shape[2]):\n",
    "    # Convert the slice to a PyTorch tensor and compute the rotation matrix\n",
    "    rotation_matrix = rotation_6d_to_matrix(torch.tensor(poses[:, :, idx]))\n",
    "    \n",
    "    # Convert the rotation matrix to axis-angle form and convert to a NumPy array\n",
    "    axis_angle = np.array(matrix_to_axis_angle(rotation_matrix))\n",
    "    \n",
    "    # Reshape the output and append to the list\n",
    "    pose_output.append(axis_angle.reshape(-1))\n",
    "\n",
    "# Convert the list to a NumPy array\n",
    "pose_output_array = np.array(pose_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a5c0ed7-ce95-4c77-a8dc-1e04caf17ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T16:23:29.548059Z",
     "iopub.status.busy": "2024-05-18T16:23:29.547818Z",
     "iopub.status.idle": "2024-05-18T16:23:29.551253Z",
     "shell.execute_reply": "2024-05-18T16:23:29.550708Z"
    }
   },
   "outputs": [],
   "source": [
    "final_dict = {}\n",
    "final_dict[\"smpl_trans\"] = transl.reshape(-1,3)\n",
    "final_dict[\"smpl_poses\"] = pose_output_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8b87ead-fbd6-4ccd-be42-4bcba82efb65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T16:23:29.553772Z",
     "iopub.status.busy": "2024-05-18T16:23:29.553570Z",
     "iopub.status.idle": "2024-05-18T16:23:29.558787Z",
     "shell.execute_reply": "2024-05-18T16:23:29.558091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary has been successfully saved and any existing file was overwritten at /home/rishabhswapnil/arah-release/aist_motion/motions/data_test.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "file_path = '/home/rishabhswapnil/arah-release/aist_motion/motions/data_test.pkl'\n",
    "\n",
    "# Open a file for writing. This will overwrite any existing file with the same name.\n",
    "with open(file_path, 'wb') as file:\n",
    "    # Use pickle to dump the dictionary into the file\n",
    "    pickle.dump(final_dict, file)\n",
    "\n",
    "print(f'Dictionary has been successfully saved and any existing file was overwritten at {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a08a32d6-7f42-421d-95af-1b4b51f411d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T16:23:29.561078Z",
     "iopub.status.busy": "2024-05-18T16:23:29.560874Z",
     "iopub.status.idle": "2024-05-18T16:23:29.564211Z",
     "shell.execute_reply": "2024-05-18T16:23:29.563727Z"
    }
   },
   "outputs": [],
   "source": [
    "mdm_data = np.load('/home/rishabhswapnil/arah-release/aist_motion/motions/data_test.pkl', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3af503be-8315-421c-ae5a-5fdc5a76de57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T16:23:29.566354Z",
     "iopub.status.busy": "2024-05-18T16:23:29.566177Z",
     "iopub.status.idle": "2024-05-18T16:23:29.572045Z",
     "shell.execute_reply": "2024-05-18T16:23:29.571423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1370, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdm_data[\"smpl_trans\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee09bbed-f556-4b08-9c63-49adde61a713",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T16:23:29.574164Z",
     "iopub.status.busy": "2024-05-18T16:23:29.573984Z",
     "iopub.status.idle": "2024-05-18T16:23:29.576529Z",
     "shell.execute_reply": "2024-05-18T16:23:29.575996Z"
    }
   },
   "outputs": [],
   "source": [
    "#final_dict[\"smpl_trans\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eee702f-5f95-4777-9177-2805c28160ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T16:23:29.578752Z",
     "iopub.status.busy": "2024-05-18T16:23:29.578552Z",
     "iopub.status.idle": "2024-05-18T16:23:29.581244Z",
     "shell.execute_reply": "2024-05-18T16:23:29.580706Z"
    }
   },
   "outputs": [],
   "source": [
    "#temp_poses = np.array(matrix_to_axis_angle(rotation_6d_to_matrix(torch.tensor(poses[:, :, 1])))).reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abf97904-3126-4e97-aaa4-bf4a200264b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T16:23:29.583358Z",
     "iopub.status.busy": "2024-05-18T16:23:29.583166Z",
     "iopub.status.idle": "2024-05-18T16:23:29.586984Z",
     "shell.execute_reply": "2024-05-18T16:23:29.586424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp_poses[0] = 0.\\ntemp_poses[1] = 0.\\ntemp_poses[2] = 0.\\nfinal_poses =np.append(final_poses,temp_poses,axis=1)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"temp_poses[0] = 0.\n",
    "temp_poses[1] = 0.\n",
    "temp_poses[2] = 0.\n",
    "final_poses =np.append(final_poses,temp_poses,axis=1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be3fe662-12c4-4821-80da-3ba12f392247",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T16:23:29.589147Z",
     "iopub.status.busy": "2024-05-18T16:23:29.588952Z",
     "iopub.status.idle": "2024-05-18T16:23:29.591628Z",
     "shell.execute_reply": "2024-05-18T16:23:29.591098Z"
    }
   },
   "outputs": [],
   "source": [
    "#final_dict[\"smpl_trans\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e10be912-e454-4ab0-84ba-cbbf28773657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T16:23:29.593786Z",
     "iopub.status.busy": "2024-05-18T16:23:29.593587Z",
     "iopub.status.idle": "2024-05-18T16:23:29.596462Z",
     "shell.execute_reply": "2024-05-18T16:23:29.595888Z"
    }
   },
   "outputs": [],
   "source": [
    "#poses = np.array(matrix_to_axis_angle(rotation_6d_to_matrix(torch.tensor(self.poses[:, :, idx])))).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51dae023-b0bc-494a-aa0f-61621d269229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-18T16:23:29.599155Z",
     "iopub.status.busy": "2024-05-18T16:23:29.598603Z",
     "iopub.status.idle": "2024-05-18T16:23:29.601625Z",
     "shell.execute_reply": "2024-05-18T16:23:29.600964Z"
    }
   },
   "outputs": [],
   "source": [
    "#thetas = mdm_data.item().get(\"thetas\")  # Get the joint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
